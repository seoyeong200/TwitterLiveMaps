{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3fb566-cb5d-4765-86ec-4d4ad86ebe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from IPython.display import display, display_pretty, clear_output, JSON\n",
    "# 공통 데이터 위치\n",
    "home_jovyan = \"/home/jovyan\"\n",
    "work_data = f\"{home_jovyan}/work/data\"\n",
    "work_dir=!pwd\n",
    "work_dir = work_dir[0]\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .config(\"spark.sql.session.timeZone\", \"Asia/Seoul\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# 노트북에서 테이블 형태로 데이터 프레임 출력을 위한 설정을 합니다\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # display enabled\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.truncate\", 100) # display output columns size\n",
    "\n",
    "# 로컬 환경 최적화\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 5) # the number of partitions to use when shuffling data for joins or aggregations.\n",
    "spark.conf.set(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\")\n",
    "\n",
    "kafkaReader = (\n",
    "    spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka:9093\")\n",
    "  .option(\"subscribe\", \"bts\")\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .load()\n",
    ")\n",
    "\n",
    "\n",
    "kafkaSchema = (\n",
    "    StructType()\n",
    "    .add(StructField(\"status\", StringType()))\n",
    "    .add(StructField(\"id\", StringType()))\n",
    "    .add(StructField(\"screen_name\", StringType()))\n",
    "    .add(StructField(\"user_id\", IntegerType()))\n",
    "    .add(StructField(\"profile\", StringType()))\n",
    "    .add(StructField(\"time\", DateType()))\n",
    "    .add(StructField(\"text\", StringType()))\n",
    "    .add(StructField(\"retweet_count\", IntegerType()))\n",
    "    .add(StructField(\"favorite_count\", IntegerType()))\n",
    "    .add(StructField(\"lat\", IntegerType()))\n",
    "    .add(StructField(\"long\", IntegerType()))\n",
    ")\n",
    "\n",
    "\n",
    "kafkaSelector = (\n",
    "    kafkaReader\n",
    "    .select(\n",
    "        col(\"key\").cast(\"string\"),\n",
    "        from_json(col(\"value\").cast(\"string\"), kafkaSchema).alias(\"movies\")\n",
    "    )\n",
    "    .selectExpr(\"movies.id as key\", \"movies.status\", \"movies.screen_name\", \"movies.user_id\", \"movies.profile\", \"movies.time\", \"movies.text\", \"movies.retweet_count\", \"movies.favorite_count\", \"movies.lat\", \"movies.long\")\n",
    ")\n",
    "\n",
    "def processing(s):\n",
    "    import re\n",
    "    s = re.compile('[^ ㄱ-ㅣ가-힣a-zA-Z0-9./%#:\\n]+').sub('',s)\n",
    "    return s\n",
    "    \n",
    "processing_udf = udf(lambda x: processing(x),StringType())\n",
    "kafkaSelector = kafkaSelector.withColumn(\"processed_text\", processing_udf(col(\"text\"))) \n",
    "kafkaSelector = (\n",
    "    kafkaSelector\n",
    "    .select(\"id\", \"user_id\", \"profile\", \"time\", \"processed_text\", \"retweet_count\", \"favorite_count\")\n",
    "    .where(\"status='ORIGINAL'\")\n",
    ")\n",
    "kafkaSelector.printSchema\n",
    "p_kafkaSelector = kafkaSelector.select(to_json(kafkaSelector.*))\n",
    "\n",
    "qname = \"temp\"\n",
    "kafkaWriter_origin = (\n",
    "    p_kafkaSelector.select(\"*\")\n",
    "    .writeStream\n",
    "    .queryName(qname)\n",
    "    .format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9093\")\n",
    "    .option(\"topic\", \"groups\")\n",
    "    .outputMode(\"append\")\n",
    ")\n",
    "checkpointLocation = f\"{work_dir}/tmp/{queryName1}\"\n",
    "!rm -rf $checkpointLocation\n",
    "kafkaTrigger = (\n",
    "    kafkaWriter_origin\n",
    "    .trigger(processingTime=\"2 second\")\n",
    "    .option(\"checkpointLocation\", checkpointLocation)\n",
    ")\n",
    "kafkaQuery = kafkaTrigger.start()\n",
    "\n",
    "for i in range(1000):\n",
    "    display(kafkaQuery.status['message'])\n",
    "    display(kafkaQuery.lastProgress)\n",
    "    \n",
    "kafkaQuery.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
